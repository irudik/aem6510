---
title: "Lecture 15"
subtitle: "Travel cost and recreation demand"
author: Ivan Rudik
date: AEM 4510
output:
  xaringan::moon_reader:
    css: ['default', 'metropolis', 'metropolis-fonts', 'my-css.css']
    # self_contained: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'

---
exclude: true
```{r setup}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  tidyverse, magrittr, xaringanExtra, rlang, patchwork, nycflights13, broom, viridis, vembedr
)
set.seed(1)
options(htmltools.dir.version = FALSE)
knitr::opts_hooks$set(fig.callout = function(options) {
  if (options$fig.callout) {
    options$echo <- FALSE
  }
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
  options
})
red_pink <- "#e64173"
blue <- "#3C93DC"
red <- "#ff0000"
```
```{r xaringanExtra, echo = FALSE}
xaringanExtra::use_xaringan_extra(c("tile_view", "panelset", "webcam"))
xaringanExtra::style_panelset(panel_tab_color_active = "red")
```
```{r themes}
red_pink <- "#e64173"
# A blank theme for ggplot
theme_empty <- theme_minimal() +
  theme(
    legend.position = "none",
    title = element_text(size = 24),
    axis.text.x = element_text(size = 24), axis.text.y = element_text(size = 24, color = "#ffffff"),
    axis.title.x = element_text(size = 24), axis.title.y = element_text(size = 24),
    panel.grid.minor.x = element_blank(), panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(),
    panel.background = element_rect(fill = "#ffffff", colour = NA),
    plot.background = element_rect(fill = "#ffffff", colour = NA),
    axis.line = element_line(colour = "black"), axis.ticks = element_line(),
  )
theme_blank <- theme_minimal() +
  theme(
    legend.position = "none",
    title = element_text(size = 24),
    axis.text.x = element_blank(), axis.text.y = element_blank(),
    axis.title.x = element_blank(), axis.title.y = element_blank(),
    panel.grid.minor.x = element_blank(), panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(),
    panel.background = element_rect(fill = "#ffffff", colour = NA),
    plot.background = element_rect(fill = "#ffffff", colour = NA),
    axis.line = element_blank(), axis.ticks = element_blank(),
  ) 
theme_regular <- 
  theme_minimal() +
  theme(
    legend.position = "none",
    title = element_text(size = 14),
    axis.text.x = element_text(size = 24), axis.text.y = element_text(size = 24),
    axis.title.x = element_text(size = 24), axis.title.y = element_text(size = 24),
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(), axis.ticks = element_line(),  axis.line = element_line(),
    panel.background = element_rect(fill = "#ffffff", colour = NA),
    plot.background = element_rect(fill = "#ffffff", colour = NA)
  ) 
```
```{r data}
# initialize seed and data
set.seed(1000)
num_trips <- 100
trip_data <- expand.grid(
  house_num = seq(from = 1, to = num_trips),
  site = 1:26
)

# make fake dataset
trip_data <- trip_data %>%
  as_tibble() %>%
  mutate(
    trips = sample(0:8, num_trips * 26, replace = TRUE),
    income = exp(rnorm(num_trips * 26)) * 3000 + 50000 + rnorm(num_trips * 2) * 15000,
    income = ifelse(income < 10000, 10000, income),
    travel_cost = exp(rnorm(num_trips * 26)) * 30,
    travel_cost_other = exp(rnorm(num_trips * 26)) * 35,
    trips = round(-.01 * travel_cost + .01 * travel_cost_other + 3 / 100000 * income),
    water_clarity = runif(num_trips * 26)
  ) %>%
  group_by(site) %>%
  mutate(water_clarity = mean(water_clarity)) %>%
  ungroup() %>%
  mutate(trips = case_when(
    trips <= 0 ~ 0,
    TRUE ~ trips + 3 * round(water_clarity)
  ))
write_csv(trip_data, "data/trip_data.csv")
```

---

# Roadmap

- How do we estimate the value of recreational goods?

---

class: inverse, center, middle
name: background

# Background

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>

---

# Should we separate the Great Lakes and Mississippi?

<div class="vembedr" align="center">
  <div>
    <iframe src="https://www.youtube.com/embed/lIRXDDG6yB8" width="800" height="450" frameborder="0" allowfullscreen=""></iframe>
  </div>
</div>

---

# Should we separate the Great Lakes and Mississippi?

.center[
```{r, out.width = "70%", fig.pos="c", echo = FALSE}
knitr::include_graphics("figures/12-carp1.png")
```
]

---

# Should we separate the Great Lakes and Mississippi?

.center[
```{r, out.width = "50%", fig.pos="c", echo = FALSE}
knitr::include_graphics("figures/12-carp2.png")
```
]

---

# Should we separate the Great Lakes and Mississippi?

Benefits from barriers accrue to anglers in the Great Lakes, both commercial and recreational 

Costs come from cost of building the barriers plus cost of maintaining them,  plus costs of reduced shipping (if any), plus any other costs associated with the barriers

How do we figure out the benefits from recreational anglers? 

---

# Why do we need travel cost?

Recreational areas .hi[have value]

--

Their quality also has value

--

Not placing a value on recreation is essentially giving it a value of .hi-purple[zero]

--

This is likely inappropriate

--

If someone dumped toxic waste in Taughannock does that have zero cost?

---

# What is the travel cost method?

The travel cost method uses observable data on recreation visitation to infer the recreational value of environmental amenities

--

The central idea is that the time and travel cost expenses that people incur to visit a site represent the .hi[price] of access to the site

--

This means that people's WTP to visit can be estimated based on the number of visits they make to sites of different prices

--

This gives us a demand curve for sites/amenities, so we can value changes in these environmental amenities

---

# Hotelling

After WWII, the U.S. national park service solicited advice from economists on methods for quantifying the value of specific park properties

--

Would total entrance fee that people pay measure the value?

--

.hi-red[No!]

--

Harold Hotelling proposed the first indirect method for measuring the demand of a non-market good in 1947

---

# Hotelling

> Let concentric zones be defined around each park so that the cost of travel to the park from all points in one of these zones is approximately constant. The persons entering the park in a year, or a suitable chosen sample of them, are to be listed according to the zone from which they came. The fact that they come means that the service of the park is at least worth the cost, and this cost can probably be estimated with fair accuracy. 

---

# Hotelling

> A comparison of the cost of coming from a zone with the number of people who do come from it, together with a count of the population of the zone, enables us to plot one point for each zone on a demand curve for the service of the park. By a judicious process of fitting, it should be possible to get a good enough approximation to this demand curve to provide, through integration, a measure of consumersâ€™ surplus.. 

--

About twelve years after, Trice and Wood (1958) and Clawson (1959) independently implemented the methodology 

---

# Theoretical foundation

Here's the theory for how we can use observed data to tell us something about willingness to pay

--

Consider a single consumer and a single recreation site

--

The consumer has:

- Total number of recreation trips: x, to site of quality: q
- Total budget of time: T
- Working time: H
- Non-recreation, non-work time: l
- Hourly wage: w
- Money cost of reaching the site: c
- Expenditures on other market goods: z


---

# Theoretical foundation

This lets us write down the consumer's utility maximization problem:
$$\max_{x,z,l} U(x,z,l,q) \,\,\,\, \text{subject to: }\,\,\, \underbrace{wH = cx + z}_{\text{money budget}}, \,\, \underbrace{T = H + l + tx}_{\text{time budget}}$$
--

Combine the two constraints to get:

--

$$\max_{x,z,l} U(x,z,l,q) \,\,\,\, \text{subject to: }\,\,\, \underbrace{wT = z + (c+wt)x + wl}_{\text{combined money/time budget}}$$

---

# Theoretical foundation

Let $Y = wT$ be the consumer's *full income*, their money value of total time budget

--

Let $p = c+wt$ be the consumer's *full price*, their total cost to reach the site

Then we can write the problem as:

--
$$\max_{x,z,l} U(x,z,l,q) \,\,\,\, \text{subject to: }\,\,\, \underbrace{Y = z + px + wl}_{\text{combined budget}}$$

--

Solve the constraint for $z$ and substitute into the utility function...

---

# Theoretical foundation

$$\max_{x,l} U\left(x,Y-px-wl,l,q\right)$$

--

This has first-order conditions:
$$[x] \,\,\, U_x - pU_z = 0 \rightarrow \frac{U_x}{U_z} = p$$

and
$$[l] \,\,\, -wU_z + U_l = 0 \rightarrow \frac{U_l}{U_z} = w$$

---

# Theoretical foundation

$\frac{U_x}{U_z} = p$ tells us the consumer equates the marginal rate of substitution between recreational trips and consumption to be the full price of the recreational trip

--

What does this mean?

--

.hi[The value of the recreational trip to the consumer, in dollar terms, is revealed by the full price p]

---

# Theoretical foundation

$U_x - pU_z = 0 \qquad -wU_z + U_l = 0$

The above FOCs are two equations, the consumer had two choices (x,l) so we had two unknowns

We can thus solve for x (and l) as a function of the parameters (p,Y,q):

$$x = f(p,Y,q)$$

This is simply the consumer's .hi-blue[demand curves] for recreation as a function of the full price p, full budget Y, and quality q

---

# Theoretical foundation

$$x = f(p,Y,q)$$

If we observe consumers going to sites of different full prices $p_1,p_2,\dots,p_n$, we are moving up and down their recreation demand curve

--

This lets us trace out the demand curve

--

Changing Y or q shifts the demand curve in or out: these are income and quasi-price effects

--

Once we have it, we can compute surplus!

---

# Zonal (single-site) model

Here's the most basic travel cost model to start

--

- Construct distance zones (i) as concentric circles emanating from the recreation site
  - Travel costs from all points within each zone to the site are sufficiently close in magnitude to justify neglecting the differences
--

- From a sample of visitors $(v_i)$ at the recreation site, determine zones of origin and their populations $(n_i)$
--

- Calculate the per capita visitation rates for each zone of origin $(t_i = (v_i/n_i))$


---

# Zonal (single-site) model

- Construct a travel cost measure $(tc_i)$ that reflects the round-trip costs of travel from the zone of origin to the recreation site (time and gas), + an entry fee $(fee)$ which may be zero and does not vary across zones

--

- Collect relevant socioeconomic data $(x_i)$ such as income and education for each distance zone

--

- Use statistical methods to estimate the trip demand curve: the relationship between per-capita visitation rates, cost per visit, [and travel costs to other sites $(tc_{si})$] controlling for socioeconomic differences

--

- $t_i = g(tc_i + fee; tc_{si}, x_i) + \varepsilon_i$ where $g$ can be linear

---

# Zonal (single-site) model

Here's a simple example of a set of zones 1-5:
```{R, sample2 scatter, echo = F, fig.width = 5, fig.height = 5, fig.align = 'center', dev = "svg"}
xy <- data.frame(x=rnorm(100),y=rnorm(100))
rmax = sqrt(max(xy$x)^2+max(xy$y)^2)
theta=seq(from=0,by=.01,to=2*pi)
ncirc=5

dat.circ = do.call(rbind,
  lapply(seq_len(ncirc),function(n){
  r <- n*rmax/ncirc
  data.frame(x=r*sin(theta),y=r*cos(theta),r=round(r,2))
}))

rr <- unique(dat.circ$r)
labels <- 1:ncirc
dat.text = data.frame(x=rr*cos(30),y=rr*sin(30),label = labels)


ggplot(xy,aes(x,y))+
   geom_path(data = dat.circ, aes(group=factor(r)), color = blue) +
   geom_text(data = dat.text, aes(label=label), vjust=-1, size = 5) +
  theme_blank
```

---

# Zonal (single-site) model

Suppose we have the following data:

```{r, echo = F}
df <- tribble(
  ~zone, ~dist, ~pop, ~cost, ~vpp,
  "A", 2, 10000, 20, 15,
  "B", 30, 10000, 30, 13,
  "C", 90, 20000, 65, 6,
  "D", 140, 10000, 80, 3,
  "E", 150, 10000, 90, 1
)
df
```

If we plot cost by visits per person, we have a measure of the demand curve...

---

# Zonal (single-site) model

.pull-left[
This is a very simple example where it happens to be an exactly straight line, most likely the data won't be this perfect

The line is simply from estimating: $$t_i = \beta_0 + \beta_1 tc_i + \varepsilon_i$$
]

.pull-right[
```{r, zonal example, echo = F, fig.width = 5, fig.height = 5, fig.align = 'center', dev = "svg"}
ggplot(data = df, aes(x = vpp, y = cost)) +
  geom_point(size = 5, color = blue) +
  geom_smooth(formula = y~x, method = "lm", se = F, color = "darkslategray") +
  theme_regular +
  labs(y = "Cost (tc)", x = "Trips per Person (t)")
```
]

---

# Zonal (single-site) model

.pull-left[
The data will most likely look like this, but even this is probably too clean

It ignores things like income, other sites, other household characteristics
]

.pull-right[
```{r, zonal example 2, echo = F, fig.width = 5, fig.height = 5, fig.align = 'center', dev = "svg"}

df_noisy <- tibble(vpp = 1:12, cost = 80 - 3*vpp + 20*runif(12))
ggplot(data = df_noisy, aes(x = vpp, y = cost)) +
  geom_point(size = 5, color = blue) +
  geom_smooth(formula = y~x, method = "lm", se = F, color = "darkslategray") +
  theme_regular +
  labs(y = "Cost", x = "Visits per Person") +
  scale_x_continuous(breaks = scales::pretty_breaks())
```
]

---

# Zonal (single-site) model

Based on the estimate model coefficients, construct the (inverse) demand curve

--

.hi[For each zone:] predict total visitation given various fees

--

Entry fee on the y-axis (price), and the number of predicted total visits on the x-axis (quantity)

--

The demand curve is different for different zone because different social economic variables

--

The (use) value of the park/site to each zone is given by the area underneath the corresponding demand curve

---

# Issues with the single-site model

What are some potential issues and concerns with this approach?

--

It ignores non-use value (automatically zero for non-users)

--

What are the right zones to choose?

--

What is the right functional form for demand?

--

How do we measure the opportunity cost of time?

--

How do we treat multi-purpose trips?

--

How do we value particular site attributes? Can't disentangle them at a single site


---

# Multi-site model

To value particular site attributes we need to have multiple sites (with different attributes!)

--

We can answer questions like:

--

What is the benefit of a fish restocking program?
  - Need to know the value of fish catch rate for visitors

--

What is the benefit of water clarity?

--

What is the benefit of tree replanting?


---

# Multi-site model

Suppose we have a dataset with a large number of individuals and sites

--

Individuals are given by $i=1,\dots,N$ and sites are given by $j=1,\dots,J$

--

We observe the number of times each individual visited each site

--

The multi-site model works as follows


---

# Multi-site model

.hi[Step 1:] Do the single-site estimation for each site:
$$T_{ij} = \beta_{0j} + \beta_{1j} tc_{ij} + \beta_{2j} tc_{sij} + \beta_{3j} x_i + \varepsilon_{ij}$$

--

.hi[Step 2:] Recover all the $\beta$s from each step 1 regression so that we have a set of J $\beta_{0j}$s for $j=1\dots,J$, $\beta_{1j}$s for $j=1\dots,J$, etc

--

These $\beta$s tell us the slope $(\beta_{1j})$ and intercept $(\beta_{0j}, \beta_{2j}, \beta_{3j})$

--

$\beta_{2j}, \beta_{3j}$ capture how the cost of substitute sites and household characteristics shift demand up and down

---

# Multi-site model

.hi[Step 3:] Take each set of $J$ coefficient estimates and use them as the dependent variable in a regression on site attributes $z$:
$$\hat{\beta}_{0j} = \alpha_{00} + \alpha_{01}z_j + \epsilon_{0j}$$
$$\hat{\beta}_{1j} = \alpha_{10} + \alpha_{11}z_j + \epsilon_{1j}$$
$$\hat{\beta}_{2j} = \alpha_{20} + \alpha_{21}z_j + \epsilon_{2j}$$
$$\hat{\beta}_{3j} = \alpha_{30} + \alpha_{31}z_j + \epsilon_{3j}$$

The $\alpha_{\times1}$ coefficients tell us how the demand curve shifts $(\alpha_{00}, \alpha_{02}, \alpha_{03})$ or rotates $(\alpha_{01})$ as we change $z$

---

# Valuing attributes with a multi-site model

.pull-left[
If we improve the quality of a site from z<sub>1</sub> to z<sub>2</sub>, demand for that site shifts up

The gain in CS, holding the cost fixed, is given by the blue area

Once we estimate demand curves, we can see how welfare changes when we alter quality characteristics!

]

.pull-right[
```{r, multi site example, echo = F, fig.width = 5, fig.height = 5, fig.align = 'center', dev = "svg"}

dwl_points <- tibble(x = c(0, 0, 20, 50),
                     y = c(80, 50, 30, 30))

ggplot() +
  geom_abline(
    intercept = 80, slope = -1,
    size = 2, color = blue
  ) +
  geom_abline(
    intercept = 50, slope = -1,
    size = 2, color = red
  ) +
  geom_polygon(data = dwl_points, aes(x = x, y = y), fill = blue, alpha = 0.25) +
  geom_hline(
    yintercept = 30,
    size = 2,
    color = "darkslategray",
    linetype = "longdash"
  ) +
  annotate("segment", x = 20, xend = 20, y = 0, yend = 30,
           linetype = "dashed", size = 1.5, color = "grey50") +
  annotate("segment", x = 50, xend = 50, y = 0, yend = 30,
           linetype = "dashed", size = 1.5, color = "grey50") +
  annotate("text", x = 25, y = 10, label = "D(z1)", size = 8) +
  annotate("text", x = 85, y = 10, label = "D(z2)", size = 8) +
  theme_empty +
  labs(y = "Cost", x = "Visits per Person") +
  scale_x_continuous(breaks = c(20,50), labels = c(expression(t[1]), expression(t[2])),
                     limits = c(0, 100), expand = c(0, 0)) +
  scale_y_continuous(breaks = 30, labels = expression(tc[i]), limits = c(0, 100))
```
]

---

# Multi-site example

```{r}
trip_data <- read_csv("data/trip_data.csv")
trip_data
```

---

# First stage estimation

```{r}
# first stage of multi-site
site_estimates <- map_dfr(unique(trip_data$site), function(site_in){
  lm(trips ~ travel_cost + travel_cost_other + income, 
     trip_data %>% filter(site == site_in)) %>% 
    broom::tidy() %>% 
    select(estimate) %>% 
    mutate(site = site_in) %>% 
    list() %>% 
    tibble_row() %>% 
    unlist() 
}) %>% 
  select(1:5) %>% 
  magrittr::set_colnames(c("intercept", "own_price", "cross_price", "income", "site"))
```

---

# First stage estimation

```{r}
site_estimates
```

---

# Take estimates, join with water clarity

```{r}
# merge in water clarity
estimation_df <- site_estimates %>% 
  left_join(trip_data %>% distinct(site, water_clarity))
estimation_df
```

---

# Second stage

```{r}
# second stage of multi-site
demand_shifts <- map_dfr(names(estimation_df)[1:4],
        function(coefficient) {
          reg_formula <- as.formula(paste0(coefficient, " ~ water_clarity"))
          lm(reg_formula, estimation_df) %>% 
            broom::tidy() %>% 
            mutate(coeff = coefficient) %>% 
            slice(2)
        }
)
```

---

# Second stage

```{r}
demand_shifts
```
The estimates column tells us how a change in water clarity (from 0 to 100%), shifts or rotates our demand curve